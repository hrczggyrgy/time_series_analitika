{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e86924d1-066f-43f9-8e2b-a56ffb0b768c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\lenovo_laptop\\anaconda3\\envs\\myenv\\lib\\site-packages (23.3.1)\n",
      "Collecting pip\n",
      "  Using cached pip-24.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Using cached pip-24.0-py3-none-any.whl (2.1 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: To modify pip, please run the following command:\n",
      "C:\\Users\\lenovo_laptop\\anaconda3\\envs\\myenv\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Updating pip\n",
    "!pip install --upgrade pip\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4d7b519-4a4b-499d-80d9-4d17f9abb973",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'neuralprophet'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Import required libraries\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mneuralprophet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NeuralProphet, set_log_level\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Disable logging messages\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'neuralprophet'"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "from neuralprophet import NeuralProphet, set_log_level\n",
    "import pandas as pd\n",
    "\n",
    "# Disable logging messages\n",
    "set_log_level(\"ERROR\")\n",
    "\n",
    "# Load and preprocess data\n",
    "dfa = pd.read_csv(\"aggregated_daily_sales.csv\")\n",
    "# Select the needed columns from the dataframe\n",
    "df = dfa[[\"ds\", \"y\"]]\n",
    "# Drop duplicates and ensure \"ds\" column is datetime format\n",
    "df = df.drop_duplicates(subset=\"ds\").assign(ds=lambda x: pd.to_datetime(x[\"ds\"]))\n",
    "\n",
    "# Model configuration\n",
    "confidence_level = 0.9\n",
    "boundaries = round((1 - confidence_level) / 2, 2)\n",
    "quantiles = [boundaries, 1 - boundaries]\n",
    "\n",
    "# Initialize model with quantiles and set plotting backend to plotly\n",
    "m = NeuralProphet(quantiles=quantiles)\n",
    "m.set_plotting_backend(\"plotly\")\n",
    "\n",
    "# Add country holidays and custom events\n",
    "m.add_country_holidays(\"EC\")\n",
    "m.add_events([\"earthquake\"])\n",
    "\n",
    "# Prepare events dataframe\n",
    "earthquake_dates = [\"2016-04-17\", \"2016-04-18\", \"2016-04-19\", \"2016-04-20\"]\n",
    "df_events = pd.DataFrame(\n",
    "    {\"event\": \"earthquake\", \"ds\": pd.to_datetime(earthquake_dates)}\n",
    ")\n",
    "\n",
    "df_all = m.create_df_with_events(df, df_events)\n",
    "\n",
    "# Fit the model and perform forecasting\n",
    "metrics = m.fit(df_all)\n",
    "df_future = m.make_future_dataframe(df_all, periods=365, n_historic_predictions=True)\n",
    "forecast = m.predict(df_future)\n",
    "\n",
    "# plotting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a211d990-98e9-499d-92f6-520bd72cdebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from neuralprophet import NeuralProphet, set_log_level\n",
    "import pandas as pd\n",
    "\n",
    "# Disable logging messages\n",
    "set_log_level(\"ERROR\")\n",
    "\n",
    "# Load and preprocess data\n",
    "dfa = pd.read_csv(\"aggregated_daily_sales.csv\")\n",
    "# Select the needed columns from the dataframe\n",
    "df = dfa[[\"ds\", \"y\"]]\n",
    "# Drop duplicates and ensure \"ds\" column is datetime format\n",
    "df = df.drop_duplicates(subset=\"ds\").assign(ds=lambda x: pd.to_datetime(x[\"ds\"]))\n",
    "\n",
    "# Model configuration\n",
    "confidence_level = 0.9\n",
    "boundaries = round((1 - confidence_level) / 2, 2)\n",
    "quantiles = [boundaries, 1 - boundaries]\n",
    "\n",
    "# Initialize model with quantiles and set plotting backend to plotly\n",
    "m = NeuralProphet(quantiles=quantiles)\n",
    "m.set_plotting_backend(\"plotly\")\n",
    "\n",
    "# Add country holidays and custom events\n",
    "m.add_country_holidays(\"EC\")\n",
    "m.add_events([\"earthquake\"])\n",
    "\n",
    "# Prepare events dataframe\n",
    "earthquake_dates = [\"2016-04-17\", \"2016-04-18\", \"2016-04-19\", \"2016-04-20\"]\n",
    "df_events = pd.DataFrame(\n",
    "    {\"event\": \"earthquake\", \"ds\": pd.to_datetime(earthquake_dates)}\n",
    ")\n",
    "\n",
    "df_all = m.create_df_with_events(df, df_events)\n",
    "\n",
    "# Fit the model and perform forecasting\n",
    "metrics = m.fit(df_all)\n",
    "df_future = m.make_future_dataframe(df_all, periods=365, n_historic_predictions=True)\n",
    "forecast = m.predict(df_future)\n",
    "\n",
    "# plotting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd8c598-1ee1-4059-b85e-cf053d9fe79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from neuralforecast.models import NBEATSx\n",
    "from neuralforecast.losses.pytorch import DistributionLoss\n",
    "from neuralforecast import NeuralForecast\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Process df DataFrame to obtain dataset for the whole period\n",
    "residuals_df = df.copy()\n",
    "residuals_df[\"residuals\"] = df[\"y\"] - forecast['yhat1'] # Adjust to use forecasted values for residuals calculation\n",
    "residuals_df[\"unique_id\"] = \"1\"\n",
    "residuals_df = residuals_df[[\"ds\", \"residuals\", \"unique_id\"]]\n",
    "\n",
    "# Instantiate the NBEATSx model with pre-defined parameters\n",
    "model = NBEATSx(\n",
    "    h=99,\n",
    "    input_size=24,\n",
    "    loss=DistributionLoss(distribution=\"Normal\", level=[80, 90]),\n",
    "    scaler_type=\"robust\",\n",
    "    max_steps=200,\n",
    "    val_check_steps=100,\n",
    "    batch_size=32,\n",
    "    windows_batch_size=1024,\n",
    "    random_seed=1,\n",
    ")\n",
    "nf = NeuralForecast(models=[model], freq=\"D\")\n",
    "\n",
    "# Fit and predict using NeuralForecast\n",
    "nf.fit(residuals_df, id_col=\"unique_id\", time_col=\"ds\", target_col=\"residuals\")\n",
    "y_hat = nf.predict(residuals_df)\n",
    "\n",
    "# Visualization of residuals and forecast\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.plot(residuals_df[\"ds\"], residuals_df[\"residuals\"], label=\"Residuals\")\n",
    "ax.plot(y_hat[\"ds\"], y_hat[\"NBEATSx\"], label=\"Forecast\", color=\"#7B3841\")\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Timestamp [t]\")\n",
    "ax.set_ylabel(\"Residuals [t]\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
